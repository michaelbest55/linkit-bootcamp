// This code is meant to upload files to the HDFS
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.{FileSystem, Path}
import scala.io.Source

object Hdfs extends App{

  def write(uri: String, filePath: String, source: String) = { 
    System.setProperty("HADOOP_USER_NAME", "hdfs")
    val path = new Path(filePath)
    val conf = new Configuration()
    conf.set("fs.defaultFS", uri)
    val fs = FileSystem.get(conf)
    val os = fs.create(path)
    println(os.getClass)
    val fp = Source.fromFile(source)
    for (line <- fp.getLines())
      os.write(line.getBytes)
    fp.close()
    fs.close()
  }

val relativePath = "setup/setup/script/test.sql"
val stream : InputStream = getClass.getResourceAsStream(relativePath)
val sqlFile : Iterator[String] = Source.fromInputStream(stream).getLines
  
  Hdfs.write("hdfs://sandbox-hdp.hortonworks.com:8020", "hdfs://sandbox-hdp.hortonworks.com:8020/user/anonymous/drivers.csv", "~/bootcamp_assessment/basic_hdfs/data-spark/drivers.csv")
  Hdfs.write("hdfs://sandbox-hdp.hortonworks.com:8020", "hdfs://sandbox-hdp.hortonworks.com:8020/user/anonymous/timesheet.csv", "~/bootcamp_assessment/basic_hdfs/data-spark/timesheet.csv")
  Hdfs.write("hdfs://sandbox-hdp.hortonworks.com:8020", "hdfs://sandbox-hdp.hortonworks.com:8020/user/anonymous/truck_event_text_partition.csv", "~/bootcamp_assessment/basic_hdfs/data-spark/truck_event_text_partition.csv")   
}
